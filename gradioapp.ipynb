{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-25T13:46:17.905925Z","iopub.execute_input":"2023-01-25T13:46:17.906393Z","iopub.status.idle":"2023-01-25T13:46:17.922403Z","shell.execute_reply.started":"2023-01-25T13:46:17.906334Z","shell.execute_reply":"2023-01-25T13:46:17.921408Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/random-image-for-testing/image2.jpg\n/kaggle/input/random-image-for-testing/image.jpg\n/kaggle/input/pretrained-resnext/resnext.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy, pandas, torch, torchvision, torchmetrics, sklearn\nfrom platform import python_version","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:46:20.269117Z","iopub.execute_input":"2023-01-25T13:46:20.269598Z","iopub.status.idle":"2023-01-25T13:46:25.275754Z","shell.execute_reply.started":"2023-01-25T13:46:20.269561Z","shell.execute_reply":"2023-01-25T13:46:25.274145Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(python_version())\nprint(numpy.__version__)\nprint(pandas.__version__)\nprint(torch.__version__)\nprint(torchvision.__version__)\nprint(torchmetrics.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:46:25.278436Z","iopub.execute_input":"2023-01-25T13:46:25.278825Z","iopub.status.idle":"2023-01-25T13:46:25.288087Z","shell.execute_reply.started":"2023-01-25T13:46:25.278788Z","shell.execute_reply":"2023-01-25T13:46:25.286610Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"3.7.12\n1.21.6\n1.3.5\n1.11.0+cpu\n0.12.0+cpu\n0.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"try:\n    import gradio as gr\nexcept: \n    !pip -q install gradio\n    import gradio as gr\n    \nprint(f\"Gradio version: {gr.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:46:25.995876Z","iopub.execute_input":"2023-01-25T13:46:25.996344Z","iopub.status.idle":"2023-01-25T13:46:53.227507Z","shell.execute_reply.started":"2023-01-25T13:46:25.996305Z","shell.execute_reply":"2023-01-25T13:46:53.226279Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mGradio version: 3.16.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms, models\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:46:53.229321Z","iopub.execute_input":"2023-01-25T13:46:53.230291Z","iopub.status.idle":"2023-01-25T13:46:53.238055Z","shell.execute_reply.started":"2023-01-25T13:46:53.230254Z","shell.execute_reply":"2023-01-25T13:46:53.236090Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_resnext():\n    model = models.resnext50_32x4d(pretrained=True)\n  \n    torch.manual_seed(42)\n    torch.cuda.manual_seed(42)\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    model.fc = nn.Sequential(\n      nn.Linear(in_features=2048, out_features=80, bias=True)\n  )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:46:53.239601Z","iopub.execute_input":"2023-01-25T13:46:53.240253Z","iopub.status.idle":"2023-01-25T13:46:53.256165Z","shell.execute_reply.started":"2023-01-25T13:46:53.240217Z","shell.execute_reply":"2023-01-25T13:46:53.255017Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = create_resnext()\nmodel = nn.DataParallel(model)\nmodel.load_state_dict(torch.load('/kaggle/input/pretrained-resnext/resnext.pth', map_location='cpu'))","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:46:53.258454Z","iopub.execute_input":"2023-01-25T13:46:53.259583Z","iopub.status.idle":"2023-01-25T13:47:05.811435Z","shell.execute_reply.started":"2023-01-25T13:46:53.259544Z","shell.execute_reply":"2023-01-25T13:47:05.810227Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/95.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5c6c62f79fe43be99633fcfa5a18df3"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"classes = ['person',\n  'bicycle',\n  'car',\n  'motorcycle',\n  'airplane',\n  'bus',\n  'train',\n  'truck',\n  'boat',\n  'traffic light',\n  'fire hydrant',\n  'stop sign',\n  'parking meter',\n  'bench',\n  'bird',\n  'cat',\n  'dog',\n  'horse',\n  'sheep',\n  'cow',\n  'elephant',\n  'bear',\n  'zebra',\n  'giraffe',\n  'backpack',\n  'umbrella',\n  'handbag',\n  'tie',\n  'suitcase',\n  'frisbee',\n  'skis',\n  'snowboard',\n  'sports ball',\n  'kite',\n  'baseball bat',\n  'baseball glove',\n  'skateboard',\n  'surfboard',\n  'tennis racket',\n  'bottle',\n  'wine glass',\n  'cup',\n  'fork',\n  'knife',\n  'spoon',\n  'bowl',\n  'banana',\n  'apple',\n  'sandwich',\n  'orange',\n  'broccoli',\n  'carrot',\n  'hot dog',\n  'pizza',\n  'donut',\n  'cake',\n  'chair',\n  'couch',\n  'potted plant',\n  'bed',\n  'dining table',\n  'toilet',\n  'tv',\n  'laptop',\n  'mouse',\n  'remote',\n  'keyboard',\n  'cell phone',\n  'microwave',\n  'oven',\n  'toaster',\n  'sink',\n  'refrigerator',\n  'book',\n  'clock',\n  'vase',\n  'scissors',\n  'teddy bear',\n  'hair drier',\n  'toothbrush']\n        \nprint(len(classes))","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:47:05.813095Z","iopub.execute_input":"2023-01-25T13:47:05.813706Z","iopub.status.idle":"2023-01-25T13:47:05.826863Z","shell.execute_reply.started":"2023-01-25T13:47:05.813657Z","shell.execute_reply":"2023-01-25T13:47:05.825440Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"80\n","output_type":"stream"}]},{"cell_type":"code","source":"from time import time\n\ndef predict(img):\n    start = time()\n    \n    newimg = transform(img).unsqueeze(dim=0)\n    model.eval()\n    with torch.inference_mode():\n        ylogit = model(newimg).detach()\n        yprob = torch.sigmoid(ylogit)\n    \n    names_with_probs = {classes[i]: float(yprob[0][i]) for i in range(len(classes))}\n    \n    predtime = time() - start\n    \n    return names_with_probs, predtime","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:47:05.828987Z","iopub.execute_input":"2023-01-25T13:47:05.830104Z","iopub.status.idle":"2023-01-25T13:47:06.319801Z","shell.execute_reply.started":"2023-01-25T13:47:05.830066Z","shell.execute_reply":"2023-01-25T13:47:06.318453Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimg = Image.open(\"/kaggle/input/random-image-for-testing/image.jpg\")\na, b = predict(img)\nprint(a)\nprint(b)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T13:47:06.321108Z","iopub.execute_input":"2023-01-25T13:47:06.321715Z","iopub.status.idle":"2023-01-25T13:47:06.729737Z","shell.execute_reply.started":"2023-01-25T13:47:06.321674Z","shell.execute_reply":"2023-01-25T13:47:06.728241Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'person': 0.9961808919906616, 'bicycle': 0.008394231088459492, 'car': 0.0032457613851875067, 'motorcycle': 0.0007554020849056542, 'airplane': 2.6222582164336927e-05, 'bus': 0.0015153619460761547, 'train': 0.00045812051394023, 'truck': 0.0006146886735223234, 'boat': 0.003916422836482525, 'traffic light': 0.00107071443926543, 'fire hydrant': 4.716109742730623e-06, 'stop sign': 0.0003976893494836986, 'parking meter': 1.2496200449199487e-22, 'bench': 0.004423732403665781, 'bird': 0.0005676937871612608, 'cat': 0.00011253609409322962, 'dog': 0.0010629582684487104, 'horse': 7.284879757207818e-06, 'sheep': 9.622477591619827e-06, 'cow': 2.604585279186722e-05, 'elephant': 7.7267063858244e-09, 'bear': 7.681362035327766e-07, 'zebra': 3.7003861308448904e-08, 'giraffe': 4.587662090216327e-07, 'backpack': 0.042271628975868225, 'umbrella': 0.00140041159465909, 'handbag': 0.003939677029848099, 'tie': 0.0034668254666030407, 'suitcase': 4.9269237933913246e-05, 'frisbee': 0.0011718012392520905, 'skis': 6.954677519388497e-05, 'snowboard': 0.00014433416072279215, 'sports ball': 0.10635136067867279, 'kite': 3.5993427900393726e-06, 'baseball bat': 0.00023539534595329314, 'baseball glove': 0.00010819070303114131, 'skateboard': 4.1329817577206995e-06, 'surfboard': 0.031198326498270035, 'tennis racket': 1.0, 'bottle': 0.0026173957157880068, 'wine glass': 0.0006653883028775454, 'cup': 0.004679007921367884, 'fork': 0.008882048539817333, 'knife': 0.011197765357792377, 'spoon': 0.007924843579530716, 'bowl': 0.0032849868293851614, 'banana': 0.00015356048243120313, 'apple': 0.001822982681915164, 'sandwich': 0.00010555762855801731, 'orange': 0.0001226690801559016, 'broccoli': 8.01135174697265e-05, 'carrot': 3.7268644518917426e-05, 'hot dog': 0.0004551985184662044, 'pizza': 0.0029217544943094254, 'donut': 2.5810298195819361e-23, 'cake': 0.004635373130440712, 'chair': 0.04504087567329407, 'couch': 0.0014928373275324702, 'potted plant': 0.007390662562102079, 'bed': 0.00013197929365560412, 'dining table': 0.002023272914811969, 'toilet': 0.00012973989942111075, 'tv': 0.0004916288307867944, 'laptop': 4.7792724217288196e-05, 'mouse': 0.0001009399420581758, 'remote': 0.0004824501811526716, 'keyboard': 0.00013232242781668901, 'cell phone': 0.0015760837122797966, 'microwave': 0.0002926281013060361, 'oven': 0.00025343094603158534, 'toaster': 3.5369283730018106e-25, 'sink': 0.0006263078539632261, 'refrigerator': 0.0001205358057632111, 'book': 0.0009329225867986679, 'clock': 0.05079123005270958, 'vase': 0.0004970971494913101, 'scissors': 4.755780117103712e-22, 'teddy bear': 6.315989594440907e-06, 'hair drier': 1.1152047731018922e-25, 'toothbrush': 0.001524402410723269}\n0.3824961185455322\n","output_type":"stream"}]},{"cell_type":"code","source":"import gradio as gr\n\nexample_list = [[\"/kaggle/input/random-image-for-testing/image.jpg\"], [\"/kaggle/input/random-image-for-testing/image2.jpg\"]]\ntitle = 'Multilabel Classifier'\ndescription = \"A ResNeXt-50 feature extractor computer vision model to identify objects present in an image out of 80 classes\"\narticle = \"Github repo-> https://github.com/Saatvik-Sinha/DSEG660-Multilabel-Classification-Challenge\"\n\ndemo = gr.Interface(fn=predict,\n                    inputs=gr.Image(type=\"pil\"),\n                    outputs=[gr.Label(num_top_classes=80, label=\"Predictions\"),\n                             gr.Number(label=\"Prediction time (s)\")],\n                    examples=example_list, \n                    title=title,\n                    description=description,\n                    article=article)\n\ndemo.launch(debug=False, share=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:07:47.545071Z","iopub.execute_input":"2023-01-25T14:07:47.545496Z","iopub.status.idle":"2023-01-25T14:07:58.614945Z","shell.execute_reply.started":"2023-01-25T14:07:47.545449Z","shell.execute_reply":"2023-01-25T14:07:58.613443Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://d6b7b25e-cca4-427f.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://d6b7b25e-cca4-427f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport shutil\n\ntry:\n    os.mkdir(\"/kaggle/working/Multilabel/\")\nexcept:\n    shutil.rmtree(\"/kaggle/working/Multilabel/\")\n    os.mkdir(\"/kaggle/working/Multilabel/\")","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:10:23.754864Z","iopub.execute_input":"2023-01-25T14:10:23.756178Z","iopub.status.idle":"2023-01-25T14:10:23.763326Z","shell.execute_reply.started":"2023-01-25T14:10:23.756122Z","shell.execute_reply":"2023-01-25T14:10:23.761581Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"/kaggle/working/Multilabel/examples\")\nfor eg in example_list:\n    name = eg[0].split('/')[-1]\n    dst = \"/kaggle/working/Multilabel/examples/\" + name\n    shutil.copy2(src=eg[0], dst=dst)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:10:24.360019Z","iopub.execute_input":"2023-01-25T14:10:24.360459Z","iopub.status.idle":"2023-01-25T14:10:24.372007Z","shell.execute_reply.started":"2023-01-25T14:10:24.360425Z","shell.execute_reply":"2023-01-25T14:10:24.370513Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"example_list = [[\"examples/\" + example] for example in os.listdir(\"/kaggle/working/Multilabel/examples/\")]\nprint(example_list)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:12:51.785184Z","iopub.execute_input":"2023-01-25T14:12:51.785731Z","iopub.status.idle":"2023-01-25T14:12:51.792359Z","shell.execute_reply.started":"2023-01-25T14:12:51.785694Z","shell.execute_reply":"2023-01-25T14:12:51.791155Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[['examples/image2.jpg'], ['examples/image.jpg']]\n","output_type":"stream"}]},{"cell_type":"code","source":"shutil.copy2(src=\"/kaggle/input/pretrained-resnext/resnext.pth\", \n                dst=\"/kaggle/working/Multilabel/resnext.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:34:14.183959Z","iopub.execute_input":"2023-01-25T14:34:14.184384Z","iopub.status.idle":"2023-01-25T14:34:14.405800Z","shell.execute_reply.started":"2023-01-25T14:34:14.184338Z","shell.execute_reply":"2023-01-25T14:34:14.404646Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/Multilabel/resnext.pth'"},"metadata":{}}]},{"cell_type":"code","source":"%%writefile \"/kaggle/working/Multilabel/model.py\"\n\nimport torch\nfrom torchvision import models\nfrom torch import nn\n\ndef create_resnext():\n    model = models.resnext50_32x4d(pretrained=True)\n  \n    torch.manual_seed(42)\n    torch.cuda.manual_seed(42)\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    model.fc = nn.Sequential(\n      nn.Linear(in_features=2048, out_features=80, bias=True)\n  )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:22:37.926998Z","iopub.execute_input":"2023-01-25T14:22:37.927569Z","iopub.status.idle":"2023-01-25T14:22:37.937850Z","shell.execute_reply.started":"2023-01-25T14:22:37.927533Z","shell.execute_reply":"2023-01-25T14:22:37.936396Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Writing /kaggle/working/Multilabel/model.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile \"/kaggle/working/Multilabel/app.py\"\nimport os\nimport torch\nfrom torch import nn\nfrom model import create_resnext\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nmodel = create_resnext()\nmodel = nn.DataParallel(model)\nmodel.load_state_dict(torch.load('resnext.pth', map_location='cpu'))\n\nclasses = ['person',\n  'bicycle',\n  'car',\n  'motorcycle',\n  'airplane',\n  'bus',\n  'train',\n  'truck',\n  'boat',\n  'traffic light',\n  'fire hydrant',\n  'stop sign',\n  'parking meter',\n  'bench',\n  'bird',\n  'cat',\n  'dog',\n  'horse',\n  'sheep',\n  'cow',\n  'elephant',\n  'bear',\n  'zebra',\n  'giraffe',\n  'backpack',\n  'umbrella',\n  'handbag',\n  'tie',\n  'suitcase',\n  'frisbee',\n  'skis',\n  'snowboard',\n  'sports ball',\n  'kite',\n  'baseball bat',\n  'baseball glove',\n  'skateboard',\n  'surfboard',\n  'tennis racket',\n  'bottle',\n  'wine glass',\n  'cup',\n  'fork',\n  'knife',\n  'spoon',\n  'bowl',\n  'banana',\n  'apple',\n  'sandwich',\n  'orange',\n  'broccoli',\n  'carrot',\n  'hot dog',\n  'pizza',\n  'donut',\n  'cake',\n  'chair',\n  'couch',\n  'potted plant',\n  'bed',\n  'dining table',\n  'toilet',\n  'tv',\n  'laptop',\n  'mouse',\n  'remote',\n  'keyboard',\n  'cell phone',\n  'microwave',\n  'oven',\n  'toaster',\n  'sink',\n  'refrigerator',\n  'book',\n  'clock',\n  'vase',\n  'scissors',\n  'teddy bear',\n  'hair drier',\n  'toothbrush']\n\nfrom time import time\n\ndef predict(img):\n    start = time()\n    \n    newimg = transform(img).unsqueeze(dim=0)\n    model.eval()\n    with torch.inference_mode():\n        ylogit = model(newimg).detach()\n        yprob = torch.sigmoid(ylogit)\n    \n    names_with_probs = {classes[i]: float(yprob[0][i]) for i in range(len(classes))}\n    \n    predtime = time() - start\n    \n    return names_with_probs, predtime\n\nimport gradio as gr\n\nexample_list = [[\"examples/\" + example] for example in os.listdir(\"examples/\")]\n\ntitle = 'Multilabel Classifier'\ndescription = \"A ResNeXt-50 feature extractor computer vision model to identify objects present in an image out of 80 classes\"\narticle = \"Github repo-> https://github.com/Saatvik-Sinha/DSEG660-Multilabel-Classification-Challenge\"\n\ndemo = gr.Interface(fn=predict,\n                    inputs=gr.Image(type=\"pil\"),\n                    outputs=[gr.Label(num_top_classes=80, label=\"Predictions\"),\n                             gr.Number(label=\"Prediction time (s)\")],\n                    examples=example_list, \n                    title=title,\n                    description=description,\n                    article=article)\n\ndemo.launch()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:34:33.982204Z","iopub.execute_input":"2023-01-25T14:34:33.982685Z","iopub.status.idle":"2023-01-25T14:34:33.992434Z","shell.execute_reply.started":"2023-01-25T14:34:33.982648Z","shell.execute_reply":"2023-01-25T14:34:33.991022Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Writing /kaggle/working/Multilabel/app.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile \"/kaggle/working/Multilabel/requirements.txt\"\n\ntorch==1.11.0\ntorchvision==0.12.0\ngradio==3.16.2","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:37:02.877287Z","iopub.execute_input":"2023-01-25T14:37:02.877711Z","iopub.status.idle":"2023-01-25T14:37:02.885209Z","shell.execute_reply.started":"2023-01-25T14:37:02.877681Z","shell.execute_reply":"2023-01-25T14:37:02.883816Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Writing /kaggle/working/Multilabel/requirements.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/working/Multilabel\"))","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:37:58.864596Z","iopub.execute_input":"2023-01-25T14:37:58.865702Z","iopub.status.idle":"2023-01-25T14:37:58.871000Z","shell.execute_reply.started":"2023-01-25T14:37:58.865659Z","shell.execute_reply":"2023-01-25T14:37:58.869984Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"['examples', 'requirements.txt', 'resnext.pth', 'app.py', 'model.py']\n","output_type":"stream"}]},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/Multilabel',\n                    'zip',\n                    '/kaggle/working/',\n                    'Multilabel')","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:45:41.756914Z","iopub.execute_input":"2023-01-25T14:45:41.757339Z","iopub.status.idle":"2023-01-25T14:45:48.037624Z","shell.execute_reply.started":"2023-01-25T14:45:41.757308Z","shell.execute_reply":"2023-01-25T14:45:48.036764Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/Multilabel.zip'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}